{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Author: [leip@](https://moma.corp.google.com/person/leip)\n",
        "* Date: 11/30/23"
      ],
      "metadata": {
        "id": "TWFt1r0WeUY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Codey models are text-to-code models from Google AI, trained on a massive code related dataset. You can generate code related responses for different scenarios such as writing functions, unit tests, debugging, autocompleting and etc. This notebook is to show you how to use Codey APIs to do tasks below.\n",
        "\n",
        "- This is an example to show you how to make a webhook cloud functions with Codey, RAG, and different retreivers.\n",
        "- Once you have this one set up, you can refer to those docs for how to deploy cloud functions and set up webhooks for Dialogflow\n",
        "- You can add those libraries in requirements.txt file in cloud functions\n",
        "\n",
        "> - Flask==2.2.2\n",
        "- Werkzeug==2.3.7\n",
        "- google-cloud-aiplatform\n",
        "- google-cloud-discoveryengine\n",
        "- langchain==0.0.236\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Dialogflow setup doc: [link](https://cloud.google.com/dialogflow/cx/docs/quick/setup),\n",
        "Cloud functions deplployment doc: [link](https://cloud.google.com/dialogflow/cx/docs/quick/setup),\n",
        "Set up webhooks for dialogflow doc: [link](https://cloud.google.com/dialogflow/cx/docs/quick/setup)\n",
        "\n"
      ],
      "metadata": {
        "id": "srtHFYeyeY5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep Work"
      ],
      "metadata": {
        "id": "OY4L5MeCgUWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "gDeLKRepgZfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaIcho0s62on"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import vertexai\n",
        "from vertexai.language_models import CodeGenerationModel\n",
        "import json\n",
        "import time\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.retrievers import GoogleCloudEnterpriseSearchRetriever as EnterpriseSearchRetriever\n",
        "from pydantic import BaseModel, Extra, Field, root_validator\n",
        "import re\n",
        "from typing import Any, Mapping, List, Dict, Optional, Tuple, Sequence, Union\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from matching_engine import MatchingEngine\n",
        "from matching_engine_utils import MatchingEngineUtils\n",
        "from langchain.chains.router import MultiRetrievalQAChain\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "VERTEX_API_PROJECT = '<project id>'\n",
        "VERTEX_API_LOCATION = '<location>'\n",
        "\n",
        "code_generation_model = CodeGenerationModel.from_pretrained(\"code-bison\")\n",
        "vertexai.init(project=VERTEX_API_PROJECT, location=VERTEX_API_LOCATION)\n",
        "\n",
        "PROJECT_ID = \"<project id>\"\n",
        "DOC_SEARCH_ENGINE_ID = \"<doc search engine id>\"\n",
        "JIRA_SEARCH_ENGINE_ID = \"<jira search engine id>\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Webhook Function with RAG and MultiRetrievalQAChain"
      ],
      "metadata": {
        "id": "rIYOK-Khgdos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step1: Set Up Utility Functions"
      ],
      "metadata": {
        "id": "2UaSB9U4gmtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for Embeddings API with rate limiting\n",
        "def rate_limit(max_per_minute):\n",
        "    period = 60 / max_per_minute\n",
        "    print(\"Waiting\")\n",
        "    while True:\n",
        "        before = time.time()\n",
        "        yield\n",
        "        after = time.time()\n",
        "        elapsed = after - before\n",
        "        sleep_time = max(0, period - elapsed)\n",
        "        if sleep_time > 0:\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "class CustomVertexAIEmbeddings(VertexAIEmbeddings, BaseModel):\n",
        "    requests_per_minute: int\n",
        "    num_instances_per_batch: int\n",
        "\n",
        "    # Overriding embed_documents method\n",
        "    def embed_documents(self, texts: List[str]):\n",
        "        limiter = rate_limit(self.requests_per_minute)\n",
        "        results = []\n",
        "        docs = list(texts)\n",
        "\n",
        "        while docs:\n",
        "            # Working in batches because the API accepts maximum 5\n",
        "            # documents per request to get embeddings\n",
        "            head, docs = (\n",
        "                docs[: self.num_instances_per_batch],\n",
        "                docs[self.num_instances_per_batch :],\n",
        "            )\n",
        "            chunk = self.client.get_embeddings(head)\n",
        "            results.extend(chunk)\n",
        "            next(limiter)\n",
        "\n",
        "        return [r.values for r in results]"
      ],
      "metadata": {
        "id": "y3WEfRlYgQ2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2: Set Up RAG Functions"
      ],
      "metadata": {
        "id": "1imiechHgtKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rag_response(query):\n",
        "    llm = VertexAI(model_name=\"code-bison\", max_output_tokens=1024, temperature=0.2)\n",
        "\n",
        "    EMBEDDING_QPM = 100\n",
        "    EMBEDDING_NUM_BATCH = 5\n",
        "    embeddings = CustomVertexAIEmbeddings(\n",
        "    requests_per_minute=EMBEDDING_QPM,\n",
        "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
        "    )\n",
        "\n",
        "    ME_REGION = \"<location>\"\n",
        "    ME_INDEX_NAME = f\"{PROJECT_ID}-me-index\"\n",
        "    ME_EMBEDDING_DIR = f\"{PROJECT_ID}-me-bucket\"\n",
        "    ME_DIMENSIONS = 768  # when using Vertex PaLM Embedding\n",
        "    mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)\n",
        "    ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
        "    print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
        "    print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")\n",
        "\n",
        "    me = MatchingEngine.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=ME_REGION,\n",
        "    gcs_bucket_name=f\"gs://{ME_EMBEDDING_DIR}\".split(\"/\")[2],\n",
        "    embedding=embeddings,\n",
        "    index_id=ME_INDEX_ID,\n",
        "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
        "    )\n",
        "\n",
        "    # Create chain to answer questions\n",
        "    NUMBER_OF_RESULTS = 3\n",
        "    SEARCH_DISTANCE_THRESHOLD = 0.6\n",
        "\n",
        "    # Expose index to the retriever\n",
        "    code_retriever = me.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": NUMBER_OF_RESULTS,\n",
        "        \"search_distance\": SEARCH_DISTANCE_THRESHOLD,\n",
        "    },\n",
        "    )\n",
        "\n",
        "    doc_retriever=EnterpriseSearchRetriever(\n",
        "    project_id=PROJECT_ID,\n",
        "    search_engine_id=DOC_SEARCH_ENGINE_ID,\n",
        "    max_documents=3,\n",
        "    )\n",
        "\n",
        "\n",
        "    jira_retriever=EnterpriseSearchRetriever(\n",
        "    project_id=PROJECT_ID,\n",
        "    search_engine_id=JIRA_SEARCH_ENGINE_ID,\n",
        "    max_documents=3,\n",
        "    )\n",
        "\n",
        "    retriever_infos = [\n",
        "    {\n",
        "        \"name\": \"codebase search\",\n",
        "        \"description\": \"Good for answering questions about the code in the codebase\",\n",
        "        \"retriever\": code_retriever\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"coding style guide\",\n",
        "        \"description\": \"Good for answering questions about coding styles such as python coding styles, java coding styles, c++ coding styles, etc\",\n",
        "        \"retriever\": doc_retriever\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"jira issues search\",\n",
        "        \"description\": \"Good for answering questions about jira issues\",\n",
        "        \"retriever\": jira_retriever\n",
        "    }\n",
        "    ]\n",
        "    DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "    Current conversation:\n",
        "    {history}\n",
        "    Human: {input}\n",
        "    AI:\"\"\"\n",
        "\n",
        "    prompt_default_template = DEFAULT_TEMPLATE.replace('input', 'query')\n",
        "\n",
        "    prompt_default = PromptTemplate(\n",
        "        template=prompt_default_template, input_variables=['history', 'query']\n",
        "    )\n",
        "    default_chain=ConversationChain(llm=llm, prompt=prompt_default, input_key='query', output_key='result')\n",
        "\n",
        "    chain = MultiRetrievalQAChain.from_retrievers(llm, retriever_infos, default_chain=default_chain)\n",
        "    result = chain(query)['result']\n",
        "    print(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "ArxTkVUvgISn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3: Set Up Webhook Functions"
      ],
      "metadata": {
        "id": "bzoiTbj1gwlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hello_world(request):\n",
        "    \"\"\"Responds to any HTTP request.\n",
        "    Args:\n",
        "        request (flask.Request): HTTP request object.\n",
        "    Returns:\n",
        "        The response text or any set of values that can be turned into a\n",
        "        Response object using\n",
        "        `make_response <http://flask.pocoo.org/docs/1.0/api/#flask.Flask.make_response>`.\n",
        "\n",
        "    Sample request:\n",
        "    {\n",
        "        \"detectIntentResponseId\":\"e9d0482d-ae09-4152-9810-8b95c0b4286c\",\n",
        "        \"intentInfo\":{\n",
        "            \"lastMatchedIntent\":\"projects/dialogflow-cx-first-run/locations/global/agents/9a61d69a-007b-4af8-bc82-1eb0643361c3/intents/626965d9-6bb3-4724-88f3-cfdfef2315d0\"\n",
        "        },\n",
        "        \"pageInfo\":{\n",
        "            \"currentPage\":\"projects/dialogflow-cx-first-run/locations/global/agents/9a61d69a-007b-4af8-bc82-1eb0643361c3/flows/00000000-0000-0000-0000-000000000000/pages/START_PAGE\"\n",
        "        },\n",
        "        \"sessionInfo\":{\n",
        "            \"session\":\"projects/dialogflow-cx-first-run/locations/global/agents/9a61d69a-007b-4af8-bc82-1eb0643361c3/sessions/0ceccc-42b-72a-023-3c781b146\",\n",
        "            \"parameters\":{\n",
        "                \"foo\":\"bar\"\n",
        "            }\n",
        "        },\n",
        "        \"fulfillmentInfo\":{\n",
        "            \"tag\":\"hello-world\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    \"\"\"\n",
        "    request_json = request.get_json()\n",
        "    print(request_json)\n",
        "\n",
        "    prompt = \"\"\n",
        "    if request_json.get('text', None):\n",
        "        prompt = request_json['text']\n",
        "\n",
        "    if request_json.get('fulfillmentInfo', None):\n",
        "        tag = request_json['fulfillmentInfo']['tag']\n",
        "        print('Tag: {}'.format(tag))\n",
        "    elif request_json.get('queryResult', None):\n",
        "        tag = 'dialogflow-es'\n",
        "        print('Dialogflow ES webhook request')\n",
        "    else:\n",
        "        return ('Unrecognized request', 404)\n",
        "\n",
        "    if tag == 'get-rag':\n",
        "        # call rag and get a response:\n",
        "\n",
        "        result = get_rag_response(prompt)\n",
        "        # Set a response\n",
        "        print(f\"debug result:{result}\")\n",
        "        response = {}\n",
        "        response['fulfillmentResponse'] = {\n",
        "            'messages': [\n",
        "                {'text': {\n",
        "                    'text': ['',\n",
        "                             '']\n",
        "                }\n",
        "                },\n",
        "                {'payload': {\n",
        "                    'message_payload_1': 'Sample payload message1 ',\n",
        "                    'message_payload_2': 'Sample payload message2'\n",
        "                }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Update session variables\n",
        "        response['sessionInfo'] = {\n",
        "            'parameters': {\n",
        "                'foo': result\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Update custom payload\n",
        "        response['payload'] = {\n",
        "            'payload_1': 'Sample payload bla1',\n",
        "            'payload_2': 'Sample payload bla2'\n",
        "        }\n",
        "        return response\n",
        "\n",
        "    elif tag == 'dialogflow-es':\n",
        "        # Set a response\n",
        "        response = {}\n",
        "        # response['fulfillmentText'] = ('This is fulfillment_text from the webhook')\n",
        "        response['fulfillmentMessages'] = [\n",
        "            {'text': {\n",
        "                'text': ['This is response 1 from the webhook',\n",
        "                         'This is response 2 from the webhook']\n",
        "            }\n",
        "            }\n",
        "        ]\n",
        "        return response\n",
        "\n",
        "    else:\n",
        "        return ('Not found', 404)"
      ],
      "metadata": {
        "id": "LG-bK5btgNyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}